{"title":"Professional Précis","markdown":{"yaml":{"title":"Professional Précis","subtitle":"Author: (Keven M. Duverglas)"},"headingText":"About the Author","containsRefs":false,"markdown":"\n\n\nHello my name is Keven Michel Duverglas, and I am Sophmore at Allegheny. A fun fact about me is that I can speak three language.\nI am looking forward to collaborating with everyone throughout the semester and get to know the dev-team well.\n\n\n# Week 1\n\n## SE1\n\n#### Summary\n\nThere's an exploration of what exactly\n\"software engineering\" means, and the reading distinguishes it not only\nfrom fields like programming and computer science but also\nshedding light on how it stands in relation to other disciplines\nwith \"engineering\" in their title. It also speaks on the matters regarding the \ngrowth of organizations and release new software. \n\n#### Reflection\n\nI am firmly convinced that this book provides insights into crafting efficient code.\nThese insights offer practical advice on how to refine one's\ncoding practices for the long term. One of the standout aspects of the book is its emphasis\non reducing redundancy in code, which not only makes the code cleaner but also easier to maintain. \n\n#### Use-Case\n\nThis book provides the tools for us to run code, allowing Chasten to evaluate and utilize it within a test-case setting.\n\n## FB1\n\n#### Summary\n\nThe initial chapter introduces core concepts of software testing, addressing the necessity,\nmethods, and assessment of software testing. Using Python and interactive notebooks, readers\nare familiarized with these principles. The chapter provides a basic my_sqrt() function, which\naims to compute the square root of a given number. A brief overview\nof understanding Python's structure and syntax is provided, followed by a practical demonstration of\nrunning the function. Readers can directly experiment with the\nfunction and observe results, while also making edits to the provided content. And this can be done through a Jupyter \nNotebook.\n\n#### Reflection\n\nThis chapter provided a comprehensive look into the world of software testing,\noffering both theoretical knowledge and hands-on tools for practical implementation.\nOne of the intriguing parts for me was the example on testing the my_sqrt() function. Implementing a square root\nfunction might appear elementary,\nbut the emphasis on the Newton–Raphson method highlighted the process behind it.\n\n#### Use-Case\n\nThe first chapter of the Fuzzing book does a solid job of laying down the basics.\nIt sets the stage for the kind of deep thinking we'll need when we start building the\nChasten tool. By mixing theory with hands-on examples, readers get a good grasp of what's\nahead. This foundation is key, making sure everyone's on the same page as we dive into the\nmore complex parts of the book.\nIt's clear that this chapter is an essential starting point for everything that follows.\n\n\n# Week 2\n\n## SE2\n\n#### Summary\n\nThe article contrasts programming with software engineering, emphasizing three primary distinctions:\ntime, scale, and trade-offs. Time emerges as a crucial factor, with software engineering often focusing\non projects with extended lifespans that shifts in technology or business trends.\nUnlike standalone programming tasks, software engineering is inherently collaborative, \nchallenges related to team dynamics, project\nmanagement, and organizational policies. As projects and teams expand, maintaining efficiency is vital.\nFurthermore, the discipline of software engineering demands intricate decision-making. Engineers face\ncomplex trade-offs, frequently operating within an environment of differing metrics.\n\n#### Reflection\n\nReading this, I can resonate with the aspects of drawbacks and trade-offs in software engineering.\nThis is evident in class where many of my colleagues often have to decide which tasks are more crucial\nto complete. Additionally, time significantly influences our work ethic and decision-making.\nIt's a constant balance of prioritizing immediate needs against long-term objectives.\n\n#### Use-Case\n\nDuring our software development, it's crucial to evaluate the trade-offs of our programming choices.\nUnderstanding the advantages and disadvantages before deployment is vital to ensure we don't\nintroduce issues into our code, and also intergate time-keeping as a habit.\n\n## FB2\n\n#### Summary\n\nTo achieve nearly perfect code coverage, we utilize a technique known as fuzzing.\nFuzzing involves generating random characters to test various input scenarios.\nThis method helps generate potential outcomes for different functions,\nlike the provided example of the cgi_decode function.\nThrough this, we determine the necessary inputs\nto achieve comprehensive code coverage in our tests.\n\n#### Reflection\n\nImplementing such testing mechanisms proves invaluable for identifying\nmaximum coverage using random fuzzing inputs. It's particularly effective\nin discovering edge cases in extensive programs with myriad input possibilities.\nHowever, it's a time-consuming approach. Hence,\nit's crucial to employ this technique only for large-scale programs that can't be\nmanually vetted, ensuring optimal time management.\n\n#### Use-Case\n\nFor our chasten tool, incorporating these tests is paramount,\nespecially as we plan to introduce numerous features throughout the term.\nIt's crucial to ensure thorough coverage before releasing the software.\nIf we decide to implement this testing methodology, we must\nbe prepared to allocate substantial classroom time and personnel to it.\n\n\n# Week 3\n\n## SE3\n\n#### Summary\n\nThis chapter delves into the infrastructure of a software engineering team, emphasizing the pivotal role of\nteamwork in achieving remarkable results and highlighting the significance of self-awareness within the team.\nThe chapter discusses the trade-offs of working alone in software\ndevelopment, including prolonged struggles and delayed error detection.\nIt also introduces the concept of collaborative nirvana, focusing on three\npillars of social interaction: humility, respect, and trust.\nThe action items suggested include regular team meetings and check-ins,\npeer mentoring and knowledge sharing, as well as the importance of acknowledging\neach team member's strengths, celebrating success, and learning from failures.\n\n#### Reflection\n\nThis chapter underscores the critical importance of collaboration and self-awareness\nin software engineering teams. It serves as a reminder that working in isolation can\nlead to challenges and hinder progress.\nEmbracing humility, respect, and trust as guiding principles for social interaction\ncan unlock the full potential of teamwork.\n\n#### Use-Case\n\nThe insights and recommendations from this chapter can be applied\nin various scenarios within a software engineering team. For instance,\nteams can implement regular meetings and check-ins to foster communication\nand collaboration. Peer mentoring and knowledge sharing can be encouraged to\nfacilitate skill development and information exchange. Additionally,\nacknowledging the strengths of each team member,\ncelebrating achievements, and using failures as opportunities for\nlearning can help create a positive and productive team culture.\n\n## FB3\n\n#### Summary\n\nFuzzing is a dynamic testing technique employed to discover defects by generating\na wide array of random inputs and subjecting them relentlessly to a target application.\nThe primary aim is to stress-test the software and unearth unexpected vulnerabilities.\nThis chapter delves into the benefits of fuzzing,\nthe roles of the fuzzer and runner components, and the advantages of applying fuzz testing to external programs.\n\n#### Reflection\n\nThe concept of fuzzing is a powerful tool in the software testing arsenal.\nBy inundating an application with diverse and often unpredictable inputs,\nfuzzing can reveal vulnerabilities that traditional testing methods might overlook. Understanding the mechanics of fuzzing,\nsuch as the fuzzer and runner components, allows testers to tailor their approach to the specific needs of the application.\n\n#### Use-Case\n\nFuzzing is an invaluable technique for identifying vulnerabilities in\nsoftware. The benefits of fuzz testing include uncovering issues like\nbuffer overflows, crashes, and security vulnerabilities. To implement\nfuzzing, the fuzzer component can be customized to generate various \ntypes of inputs, such as numbers or characters. The runner component plays\na critical role in executing the target application with the generated inputs\nand monitoring its behavior.\n\n# Week 4\n\n## SE4\n\n#### Summary\n\nIn software development, effective communication within your team is crucial.\nTeam members are more likely to have solutions to issues because they work on\nthe same project. However, various challenges can hinder this communication,\nsuch as fear of making mistakes, withholding code sections, and dealing with broken code.\nTo address these challenges, the article proposes different communication solutions.\nThe best approach involves comprehensive documentation paired with knowledgeable \nindividuals who can apply this information to specific problems. This ensures a\nwealth of information is available, and team members can get personalized help.\nAdditionally, creating a comfortable environment where team members feel free\nto ask questions is crucial. Assigning mentors to new team members facilitates\none-on-one interactions and promotes growth.\n\n#### Reflection\n\nThis article holds significant importance for our work on the \"Chasten\" project.\nEffective communication is vital, especially given our limited time together each\nweek. While we've managed reasonably well so far, there's room for improvement.\nOften, we struggle to make information widely available, particularly concerning\nindividual pull requests and issues in the issue tracker. This can lead to various problems, such as\ninformation loss when team members are absent or leave, and the need for others\nto review the information, potentially resulting in redoing work. Another in need of improvement is organization\nof all the information that we have gathered, then it can be available to others\nthat would like to add to what we have built.\n\n#### Use-Case\n\nIn the Chasten project, we're taking practical steps to boost collaboration,\ndrawing insights from the article on effective software development team communication. \nWe're focused on creating comprehensive project documentation, implementing a mentorship\nprogram or more leaders for the project, encouraging open communication, refining issue tracking, and centralizing project\ninformation. Our aim is to foster better knowledge sharing, reduce information gaps during\ntransitions, streamline issue resolution, enhance information access, and empower team members to guide one another.\nThrough these efforts, we seek to strengthen our teamwork and productivity in the Chasten project.\n\n\n## FB4\n\n#### Summary \n\nThe section on mutation analysis explores the creation of programs to rigorously test test cases.\nIneffective testing can lead to seemingly complete test coverage while missing essential bug detection.\nTo overcome this, mutation analysis programs are introduced to temporarily inject errors into the code,\nassessing the test cases' bug-finding capabilities. The article exemplifies this with a triangle\nclassification program, standardizing the function through parsing and mutation,\nleading to the replacement of return statements with pass statements to provoke errors and gauge test case accuracy.\n\n#### Reflection\n\nThis article underscores the importance of mutation analysis in the Chasten project,\nwhere accommodating diverse user inputs, including complex XPATH expressions, is\nparamount. Ensuring robust and comprehensive test coverage capable of identifying\na wide array of errors is critical. Furthermore, considering the integration of external functions that simplify\nthe intricacies of mutation analysis into the project's software development can\nmarkedly improve the code's overall quality.\n\n#### Use-Case\n\nIn the context of the Chasten project, implementing mutation analysis is pivotal for bolstering test coverage\nand error detection across a spectrum of user inputs, including XPATH expressions.\nEmbracing the methodologies outlined in this article empowers the project to enhance\nits testing procedures, thereby fortifying its ability to identify diverse types of\nerrors. Furthermore, the integration of external functions that streamline\nthe complexities of mutation analysis can expedite the software development process\n ultimately leading to higher-quality code.\n\n# Week 5\n\n## SE5\n\n#### Summary\n\nThis chapter delves into Google's shortcomings in achieving an inclusive\nstandard and offers a roadmap for future rectification as a collective company\nendeavor. Google's software engineer demographics don't mirror their user base,\nleading to the infusion of biases into their projects, like facial recognition\nsoftware. To address this, the Value Versus Outcomes section presents key\nconsiderations: evaluating the composition of the product development team in\nrelation to the end users, designing for the most challenged user to enhance accessibility,\nscrutinizing data for success, and identifying and preventing future failure points. These\nguidelines amalgamate into a call for software engineers to be part of the solution rather thanthe problem, ultimately\nfostering equity in their endeavors. The chapter also provides reflections and suggestions for further action.\n\n#### Reflection\n\nThis chapter underscores the importance of inclusive workplaces\nfor productivity and bias reduction, with software engineers as\nkey agents of change. It emphasizes the need to address bias, shift from\n\"building for\" to \"building with\" everyone, and tackle systemic tech industry\nissues through psychological safety, multicultural competence, and professional\ngrowth. The chapter highlights the significance of engineers\ncomprehending their products' impact on diverse users,\nemphasizing the value of inclusive work environments and ongoing\nlearning for personal and career development.\n\n#### Use-Case\n\n\nThis chapter underscores the importance of inclusivity in product development,\nemphasizing a user-centric approach and collaboration with diversity experts.\nWhile it may not directly apply to our current project, it's vital for workforce\nreadiness. For Chasten's future users, particularly\nAllegheny College students, we must prioritize code readability and\nuse our experience to improve accessibility for a wider audience.\n\n## FB5\n\n#### Summary\n\nWhen fuzzing programs that accept more than just random inputs,\nlike website URLs, it's crucial to adapt our fuzzer to produce\nrealistic yet incorrect URLs for testing functions related to URLs.\nAttempting to test such functions with entirely random inputs could\ntake years to stumble upon a correct HTTP URL. An effective strategy\ninvolves taking valid inputs and strategically altering specific\ncharacters to create URLs that are incorrect but closely resemble\nthe correct format. This approach allows us to generate a wide\narray of input variations. When these diverse inputs are combined\nwith a runner function, they ensure comprehensive coverage of every\nline within the function under test. Consolidating these techniques\ninto a mutation fuzzing function enables the integration of knowledge\nand methods from mutation analysis, code coverage analysis, and fuzzing\ninto a unified and effective testing approach.\n\n#### Reflection\n\nThis article explores the integration of previously acquired knowledge\ninto a single function known as mutation fuzzing. The importance of\nincorporating these ideas into test cases is emphasized to ensure\ncomprehensive coverage of various XPATH expressions. Mutation fuzzing\nallows for the rapid application of these techniques on a large scale,\nenabling the implementation of tests that would be impractical to conduct \nmanually.\n\n#### Use-case\n\nMutation fuzzing serves as a valuable tool in software testing and security analysis,\nparticularly for applications relying on XPATH expressions. It automates the generation\nof diverse inputs, enabling systematic evaluation and rapid identification of vulnerabilities,\nensuring software robustness. Its scalability and efficiency make it an indispensable\nresource for uncovering edge cases and enhancing security.\n\n# Week 6\n\n## SE6\n\n#### Summary\n\nThe section from \"Software Engineering at Google\" stresses the importance of leadership\nwithin any team, especially in software development contexts. It acknowledges the phenomenon\nwhere engineers, often reluctantly, assume managerial roles. The dual mastery of software\nengineering skills and team management is crucial for success. A key focus is on the subtleties\nof effective management, advocating against micromanagement. Instead, a successful manager\nshould aim to create a supportive work environment, providing flexibility and removing impediments\nto streamline workflows. The importance of maintaining a professional yet approachable relationship\nwith team members is also emphasized, which helps in making tough decisions without compromising\nteam dynamics. The chapter crystallizes its guidance into three fundamental principles for leadership:\nHumility, Trust, and Respect. These principles ensure a leader is supportive and reliable, allowing team\nmembers to focus on their tasks without undue concern about managerial issues.\n\n#### Reflection & Use-case\n\nIn our own setting, the traditional hierarchical structure of managers and subordinates is absent.\nHowever, we often find ourselves in leadership roles within peer-driven projects, particularly when we\npossess specialized knowledge. In these scenarios, it's important to apply the principles of respect and\nhumility. Our approach should be one of collaboration and learning, rather than asserting dominance or\npower. This ensures a more harmonious and productive environment, where knowledge transfer is effective\nand team dynamics are positive. By embracing these values, we can foster a healthy and efficient workspace,\neven in the absence of formal leadership roles.\n\n## FB6\n\n#### Summary\n\nThis chapter focuses on the interplay between formal languages, universal grammars,\nand their role in generating inputs, segueing into a detailed exploration of grammars.\nIt emphasizes the significance of grammars in not only constructing programming languages\nbut also in formulating structured inputs for testing. Defining a grammar allows for the\ncreation of a function that generates random, yet structurally sound inputs, facilitating\nextensive code testing. Nevertheless, this method has its boundaries. To optimize its utility,\n\\mutating these inputs is suggested, providing a more thorough examination of the code's\nconstraints and capabilities.\n\n#### Reflection\n\nThe application of grammars in this context was an unexpected revelation to me,\nhaving not considered this possibility when I initially encountered the concept.\nThe deeper I delve into the Fuzzing Book, the more it resembles assembling pieces\nof a puzzle, each piece contributing to the creation of a robust testing suite.\n\n#### Use-case \n\nAs we venture into our new project, it seems opportune to integrate some of these insights.\nImplementing these grammatical structures to generate test inputs could enhance our testing\nprocess, ensuring a more robust and comprehensive evaluation of our code. It's an intriguing\napproach worth exploring to strengthen our project's overall quality and reliability.\n\n# Week 7\n\n## SE7\n\n#### Summary\n\nThis chapter highlights\nstrategies like identifying limiting factors, making informed trade-offs, and iterating ideas\nto strike a balance. A crucial goal is to develop a self-driving team, reducing the 'bus factor'\nby creating subteams for diverse problem-solving. Additionally, the chapter advises on scaling\nteam sizes based on project demands, ensuring neither team members nor leaders are overwhelmed.\n\n#### Reflection & Use-case\n\nFrom this chapter, the standout insight is that effective management comprises observation\nand listening, with just a little being critical adjustments. This principle discourages micromanagement\nand promotes responsive leadership based on team feedback, fostering efficiency and autonomy.\nHowever, its direct relevance to our Chasten project is limited, as we operate without a set leader,\nassigning tasks within small groups for self-driven progress. While the chapter targets environments\nwith clear leadership hierarchies, its emphasis on minimal but meaningful interventions and team\nautonomy can still offer useful insights for our collaborative efforts in developing the Chasten tool.\n\n## FB7\n\n#### Summary\n\nThe chapter addresses the inefficiencies of the simple_grammar_fuzzer in the Fuzzing Book, highlighting\nits poor time complexity with large inputs and frequent inaccuracies in symbol or parenthesis counts.\nTo remedy this, the introduction of deviation trees is proposed. These trees track the pathways of grammar\nexpansions, enabling the monitoring of each grammar statement's cost. This methodology empowers us to preset\nexpansion limits and determine when to terminate the grammar, effectively controlling input size and reducing evaluation time.\n\n#### Reflection & Action\n\nIncorporating deviation trees revolutionizes grammar fuzzing by imposing input size constraints,\ntransforming it into a practical testing method. Without such limits, grammar fuzzing risks becoming\nan endless process with increasingly large inputs, leading to significant time inefficiencies. This\ninnovation ensures that inputs remain manageable in length and can be processed within reasonable\ntimeframes, greatly enhancing the utility and applicability of this testing technique.\n\n# Week 8\n\n## SE8\n\n#### Summary\n\nIn this section of Software Engineering at Google, the focus is on the strategic application of\nrules to optimize code quality. Rules serve as essential guidelines, distinguishing what should\nbe promoted and what should be avoided. These guidelines also prompt companies to reflect on their\ncore values, enabling the incorporation of these principles into the guidance provided to their workforce.\nA well-defined set of rules is imperative to prevent codebases from becoming chaotic and lacking a discernible pattern.\nStandardizing the execution of projects and managing a company becomes achievable by creating a style guide. This ensures\nalignment across the organization, fostering a unified approach to program implementation.\n\nUltimately, establishing robust rules that are easy to follow while maintaining a consistent set of policies\nwithin the workplace is crucial. These rules form the foundation for the team's approach to future projects,\nensuring steady production over time.\n\n#### Action & Reflection\n\nThis section resonates with our Chasten project, as our team frequently experiences challenges in achieving consensus.\nHaving a concise set of rules could greatly benefit us. For example, implementing rules related to the approval of pull\nrequests and workflow standards could lead to a more consistent and efficient team. Such changes would unify our team,\nstreamlining the collaborative process in team-based software engineering without the need for laborious efforts to seek\nteam members' assistance in specific aspects.\n\n## FB8\n\n#### Summary\n\nIn specific scenarios of fuzz testing, relying solely on a grammar fuzzer may not suffice due to the inherent need\nfor rules in input generation. To address this, employing a parser becomes essential to transform a string input\ninto a derivation tree. A Predicate Expression Grammar (PEG) parser serves this purpose, parsing until it identifies\na rule that aligns with its query. An example is provided below:\n\n```python\nclass PEGParser(Parser):\n    def parse_prefix(self, text):\n        cursor, tree = self.unify_key(self.start_symbol(), text, 0)\n        return cursor, [tree]\n```\n\nWhile PEGParser is effective for finding a single match, in many cases, it is desirable to identify all matches,\nnecessitating a Context-Free Grammar (CFG) parser. This type of parser allows for matching all parts of an input\nduring parsing, as illustrated by the following example:\n\n```\nclass CFGParser(CGFParser):\n    def parse(self, text):\n        cursor, states = self.parse_prefix(text)\n        start = next((s for s in states if s.finished()), None)\n\n        if cursor < len(text) or not start:\n            raise SyntaxError(\"at \" + repr(text[cursor:]))\n\n        forest = self.parse_forest(self.table, start)\n        for tree in self.extract_trees(forest):\n            yield self.prune_tree(tree)\n```\n\n#### Action & Reflection\n\nThese parsers represent a crucial advancement in creating derivation trees from specific seeded inputs.\nThis capability enables the identification of necessary grammars for simulating inputs in future fuzz testing,\nautomating the input-taking process for subsequent fuzzing. In the context of Chasten, integrating PEG and CFG\nparsers enhances the tool's performance by facilitating the\nimportation and seamless implementation of these parsers. These parsers contribute to the creation of concise,\nbranched grammars, leading to faster grammar processing times. The incorporation of more complex parsers allows\nfor the composition of grammars with finer details, without compromising external structures or the program's\noverall significance.\n\n## SE9\n\n#### Summary\n\n\nThis segment of Google's Software Engineering focuses on the pre-merger evaluation of code for the main product.\nIt encompasses insights into the advantages, recommendations, and overall procedures employed by Google to optimize\nthe efficiency and effectiveness of code reviews. Google employs a meticulous approach to guarantee correctness,\nconsistency, extensive knowledge sharing among developers, and comprehensive change tracking. While this process\nincurs costs, it ensures that the codebase adheres to Google's high standards of consistency.\n\nHowever, the journey of code review is not always seamless. Consequently, this section provides valuable\ntips for conducting reviews effectively. Essential to this is maintaining a courteous and professional\ncommunication style to facilitate timely and dispute-free code reviews. Code reviewers are advised to\ncommunicate their review timelines promptly, ensuring that others are not left waiting. Professionalism\nbecomes crucial when disagreements arise between a developer and a reviewer regarding a specific section of\ncode; finding common ground on necessary changes is essential. Emphasizing the importance of modest changes\nis another key point, preventing reviewers from feeling overwhelmed and facilitating swift reviews. Crafting\ninformative commit messages and change descriptions proves instrumental in aiding reviewers' understanding of\nthe nature of the changes. Additionally, prudent resource usage is stressed, advocating for a single reviewer\nand the automation of tasks wherever possible.\n\n#### Action & Reflection\n\nThis section highlights crucial insights into efficient code review practices. One notable aspect that caught\nmy attention pertains to the number of reviewers involved in the process. In our current project, we maintain\na minimum of 3 reviewers, and at times, this number escalates to 5 for a single change. This approach is\nflagged as inefficient in the article, emphasizing that often, reviewers merely skim through the code to\nverify functionality rather than conducting a thorough examination. Consequently, multiple individuals spend\ntime perfunctorily reviewing code that could be adequately handled by a single person. Addressing this\ninefficiency involves considering a shift to single-person reviews, which not only streamlines the process\nbut also holds that individual accountable for timely and accurate reviews.\n\nAnother noteworthy point discusses the importance of precise change descriptions, an area where our\nteam appears to be lacking. Specifically, commit messages and timing are identified as potential weaknesses.\nThe suggestion is to increase the frequency of commits to showcase each incremental change to specific code\nsegments. This practice enables reviewers to track the evolution and improvement of the change step by step,\nfostering a clearer understanding of the development process. Implementing these adjustments could contribute\nto a more streamlined and accountable code review process within our team.\n\n## FB9\n\n#### Summary\nWhen employing tests to intentionally induce code failures or crashes, it's crucial to grasp the underlying\nreasons for the failure and understand the conditions that trigger it. Mere awareness of a broken state isn't\nsufficient; one must delve into the hows and whys of the issue. While running tests, pinpointing the specific\nsegments of the code responsible for problems can be challenging. A fuzzer or mutator-based approach might\nidentify the existence of an issue but often falls short in providing insights into the reasons behind the problem.\n\nTo tackle this, manual exploration can be undertaken, where testing continues until the problem is uncovered.\nAlternatively, a technique known as Delta Debugging can be applied. This method takes the inputs responsible\nfor breaking the test or build and employs a binary search algorithm-like approach. It systematically removes\nparts of the input to determine if the issue persists or is resolved. Delta Debugging aids in identifying the\ncauses of a bug or defect, streamlining more efficient and targeted fixes if necessary.\n\nAn illustrative example of Delta Debugging is found in the [Fuzzingbook](https://www.fuzzingbook.org/):\n\n```python\nclass DeltaDebuggingReducer(CachingReducer):\n    \"\"\"Reduce inputs using delta debugging.\"\"\"\n\n    def reduce(self, inp: str) -> str:\n        \"\"\"Reduce input `inp` using delta debugging. Return reduced input.\"\"\"\n\n        self.reset()\n        assert self.test(inp) != Runner.PASS\n\n        n = 2     # Initial granularity\n        while len(inp) >= 2:\n            start = 0.0\n            subset_length = len(inp) / n\n            some_complement_is_failing = False\n\n            while start < len(inp):\n                complement = inp[:int(start)] + \\\n                    inp[int(start + subset_length):]\n\n                if self.test(complement) == Runner.FAIL:\n                    inp = complement\n                    n = max(n - 1, 2)\n                    some_complement_is_failing = True\n                    break\n\n                start += subset_length\n\n            if not some_complement_is_failing:\n                if n == len(inp):\n                    break\n                n = min(n * 2, len(inp))\n\n        return inp\n```\nThis code takes an input, tests it, and iteratively reduces it until it is minimized to a single character.\nThis approach enhances the specificity and usefulness of debugging outputs, providing better insight into\nthe code's behavior during failures.\n\n\n#### Action & Reflection\n\nThis concept seems somewhat beneficial, but considering the specific context in which we would apply it,\nI find that implementing this idea might involve more effort than the relatively minimal gain it offers.\nWhile it provides assistance, we're not dealing with highly intricate inputs, and the setup time for such a\nconcept may outweigh the benefits compared to manually resolving issues. Nevertheless, the core concept of\nreduction itself holds significance in debugging. It serves as an effective approach to identify problems and\noften contributes to a deeper understanding of the code. However, the automated implementation of this concept\nappears overly complex and may not be worth the effort for projects of the scale we are currently working on.\n\n# Week 9\n\n## SE10\n\n#### Summary\n\nThis section of Google's Software Engineering underscores the crucial role of documentation in enhancing\ncode usage and maintenance. Documentation goes beyond code operations, encompassing descriptive notes and\ntutorials to improve overall readability. While its benefits may not be immediately apparent, neglecting\nor delaying documentation can lead to confusion for future developers. Google emphasizes treating documentation\nlike code, with regular maintenance and adherence to a consistent style. Assigning owners to each documentation\nsection ensures ongoing clarity and long-term viability.\n\nUnderstanding the target audience is vital in documentation creation, considering factors like the audience's\nlevel of development experience and whether documentation is for internal developers or the general public.\nThe choice of documentation style is equally important, ranging from reference documentation and design documents\nto in-depth tutorials and conceptual documentation. Ensuring documentation stays current with regular updates is\nkey to its continued effectiveness, aiding users in comprehending all aspects of the tool. In conclusion, while\ncreating documentation requires initial effort, its long-term benefits in facilitating code understanding and\nusage make it a worthwhile endeavor.\n\n#### Action & Reflection\n\nWithin our Cellveyor team, our documentation efforts have room for improvement. While we've been diligent in\ncommenting on the project's work and incorporating reference documentation within the code, we haven't established a\ndedicated wiki for comprehensive documentation, including tutorials on how Cellveyor operates and reference\ndocumentation detailing the various inputs for its commands. This aspect is certainly an area where enhancement is\npossible, but I believe prioritizing it should come after addressing the remaining issues with the tool itself.\n\n## DB1\n\n#### Summary \n\nIn the inaugural section of the Debugging Book, foundational principles of troubleshooting malfunctioning\nfunctions are introduced. The discussion starts by highlighting counterproductive coding practices, such as\nexcessive print statements, arbitrary changes, and hardcoded inputs. Instead, the emphasis is on a meticulous\ncode review approach, seeking to identify root causes rather than opting for temporary fixes. Effectively\nisolating specific issues from broader exceptions entails scrutinizing generalized errors within a function\nand involves formulating, adjusting, and challenging hypotheses about the program's malfunction. Running tests\nbased on these hypotheses aids in identifying correlated issues that need resolution. Once these issues are\nfound, updating the failed test cases enhances coverage and prevents potential errors in future updates.\nMaintaining a comprehensive log of these steps facilitates the recall of previously explored ideas and actions.\n\n#### Action & Reflection\n\nWhile I already incorporate many of these bug-fixing steps into my process, a significant insight from\nthis article was the emphasis on creating a hypothesis for the reasons behind certain function failures.\nThe suggestion of adopting a higher level of documentation and a structured process for each specific issue\nappears highly beneficial, particularly when tackling complex problems. This approach not only aids in my\nindividual problem-solving but also enhances collaboration when others join in to address the issue. In essence,\nincorporating a more detailed approach within our team's issue-resolution strategy promises to yield substantial\nimprovements.ured process for each specific issue appears highly\nbeneficial, particularly when tackling complex problems. This approach not only aids in my individual\nproblem-solving but also enhances collaboration when others join in to address the issue. In essence,\nincorporating a more detailed approach within our team's issue-resolution strategy promises to yield substantial\nimprovements.\n\n# Week 10\n\n## SE11\n\n#### Summary \n\nThis section delves into testing practices at Google, highlighting the incorporation of automated programs\nto examine their extensive codebase for errors. Automated tests play a crucial role in ensuring code correctness,\noffering enhanced confidence and contributing to a smoother development process. When designing tests, Google\nconsiders their size and scope. Tests can be small, covering one process, medium, encompassing a single machine,\nor large, running on multiple machines or processes. Google advocates a majority of code coverage by narrower\nscope tests for more targeted and effective testing, as larger tests are often weaker and time-consuming.\n\n#### Action & Reflection\n\nThe testing concepts presented in this article are highly beneficial and can be effectively applied to our project, Cellveyor\n. While we have implemented both large and small-scale tests, the crucial insight here is the emphasis on not just expanding\ntest coverage but also prioritizing the creation of high-quality tests capable of handling diverse inputs. A key approach to\nachieving this is by concentrating on essential functions and incorporating fuzzing tests, which provide a variety of example\ninputs to ensure robust testing.\n\n## DB2\n\n#### Summary \n\n\nThis section of the Debugging Book delves into the use of tracers for examining variable states throughout different sections of\ncode. An illustrative example involves simple tracking of variables as the program progresses, enhancing debugging efforts by\nrevealing interactions between various variables. A more detailed version demonstrates tracing at specific points in the code,\noffering insights into variable changes:\n\n```python \nreturn 255 remove_html_markup {'s': 'abc', 'tag': False, 'quote': False, 'out': 'abc', 'c': 'c'}\n```\n\nThis meticulous tracking approach reports each instance of variable changes, providing a comprehensive understanding of program\nbehavior. While effective, this method can be time-consuming. To mitigate this, static code injection is introduced, injecting code\nselectively to trace only the necessary parts of the function, significantly reducing program runtime while maintaining detailed\ninsights into variable changes:\n\n```python\n243     for c in s:\n                                         # c = '/'\n244         assert tag or not quote\n246         if c == '<' and not quote:\n    ...\n255     return out\nremove_html_markup() returns 'x'\n```\n\n#### Action & Reflection\n\nTracing a program proves to be an effective method for monitoring the outputs of individual functions, facilitating the debugging\nprocess by providing insights into how variables interact. However, consistently running a tracer for every output can be inefficient\ndue to the time required to track all variables. Implementing tracers selectively into our project, particularly when errors occur,\nwould be highly beneficial in optimizing the debugging process.\n\n# Week 11\n\n## SE12\n\n#### Summary\n\nThis chapter delves into the concept of unit tests and strategies for their long-term maintenance. Poorly designed tests can pose\nchallenges for engineers when addressing issues arising from brittle tests. To mitigate this, the chapter suggests establishing\na test base that remains unchanged, ensuring that test cases consistently validate a function's input and output without altering\nthe method of achieving this. Preventing functions from being refactored in ways that alter their overall functionality maintains\nthe functional integrity of tests. Testing the public version of the program, rather than the private version, is recommended to\nensure the correct results are delivered to users.\n\nEffective testing also involves running state tests that assess the overall system state after program execution. For instance,\na test adding a user to a database should verify a change in the database to confirm the function's success. Writing clear tests\nwith detailed notes and a distinct purpose enhances their strength and aids engineers in quickly identifying issues. Lastly,\nthe chapter emphasizes the importance of adhering to the DRY principle (Don't Repeat Yourself) by avoiding test or function repetition.\nInstead, tests should be DAMP (Descriptive and Meaningful Phrases), prioritizing larger, more comprehensive tests over multiple similar\ntests with slight deviations to optimize the test suite.\n\n#### Action & Reflection\n\nAll these insights prove invaluable when contemplating the creation of test cases within a large program. The concept that resonated with\nme the most is the emphasis on DRY, advocating against repetition in testing. It is crucial to strive for in-depth tests while maintaining a\nfocus on a specific area of code. I am confident that we can enhance our implementation of these ideas in Cellveyor, ensuring that our test\ncases are not only concise but also free from unnecessary repetition.\n\n## DB3\n\n#### Summary\n\nThis chapter explores the concept of unit tests and their long-term maintenance strategies.\nA poorly designed test can create challenges for engineers, and the chapter suggests establishing\nan unchanging test base to ensure consistent validation of a function's input and output. The focus\nis on preventing functions from being refactored in ways that alter their overall functionality,\nmaintaining the functional integrity of tests. Testing the public version of the program, as\nopposed to the private version, is recommended to ensure the correct results are delivered to users.\nEffective testing includes running state tests that assess the overall system state after program\nexecution. Clear tests with detailed notes and a distinct purpose are encouraged to enhance their\nstrength and aid engineers in quickly identifying issues. Lastly, adherence to the DRY principle\n(Don't Repeat Yourself) and the importance of avoiding test or function repetition is emphasized.\nTests should be DAMP (Descriptive and Meaningful Phrases), prioritizing larger, more comprehensive\ntests over multiple similar tests with slight deviations to optimize the test suite.\n\n#### Action & Reflection\n\nAll these insights are valuable when considering the creation of test cases within a large program.\nThe emphasis on DRY, advocating against repetition in testing, resonates as a crucial concept. Striving\nfor in-depth tests while maintaining a focus on a specific area of code is essential. I am confident that\nwe can enhance our implementation of these ideas in Chasten, ensuring that our test cases are not only concise\nbut also free from unnecessary repetition.\n\n\n# Week 12\n\n## DB4\n\n## Summary\n\nThe introduction to the section on statistical debugging explores the process of debugging a program that intermittently\npasses and fails. The recommended approach involves identifying the lines of code that execute during failures but not\nduring passes, thereby efficiently pinpointing potential bugs and streamlining the debugging process. Utilizing a collector\nfunction helps track all lines executed when a function runs with specific inputs, enabling the identification of\ndifferences in executed lines between passing and failing inputs.\n\nThe method involves ranking lines by suspiciousness, evaluating how frequently certain lines run in a substantial\nset of failing inputs versus passing inputs. With tools like discrete or continuous spectra, developers can highlight\nthe line of code most likely to contain a bug. Statistical debugging techniques extend beyond code coverage, utilizing\nvariables and their changes to analyze failing runs and employing training algorithms to assign values to lines and identify error-prone lines.\n\n## Action & Reflection\n\nThese methods prove highly effective in identifying failure points in programs and can significantly save debugging time.\nWhile the integration of test cases employing these methods into the codebase is uncertain, their potential usefulness in\npinpointing error-prone sections, especially in a codebase the size of Cellveyor's, is evident.\n\n","srcMarkdownNoYaml":"\n\n# About the Author\n\nHello my name is Keven Michel Duverglas, and I am Sophmore at Allegheny. A fun fact about me is that I can speak three language.\nI am looking forward to collaborating with everyone throughout the semester and get to know the dev-team well.\n\n\n# Week 1\n\n## SE1\n\n#### Summary\n\nThere's an exploration of what exactly\n\"software engineering\" means, and the reading distinguishes it not only\nfrom fields like programming and computer science but also\nshedding light on how it stands in relation to other disciplines\nwith \"engineering\" in their title. It also speaks on the matters regarding the \ngrowth of organizations and release new software. \n\n#### Reflection\n\nI am firmly convinced that this book provides insights into crafting efficient code.\nThese insights offer practical advice on how to refine one's\ncoding practices for the long term. One of the standout aspects of the book is its emphasis\non reducing redundancy in code, which not only makes the code cleaner but also easier to maintain. \n\n#### Use-Case\n\nThis book provides the tools for us to run code, allowing Chasten to evaluate and utilize it within a test-case setting.\n\n## FB1\n\n#### Summary\n\nThe initial chapter introduces core concepts of software testing, addressing the necessity,\nmethods, and assessment of software testing. Using Python and interactive notebooks, readers\nare familiarized with these principles. The chapter provides a basic my_sqrt() function, which\naims to compute the square root of a given number. A brief overview\nof understanding Python's structure and syntax is provided, followed by a practical demonstration of\nrunning the function. Readers can directly experiment with the\nfunction and observe results, while also making edits to the provided content. And this can be done through a Jupyter \nNotebook.\n\n#### Reflection\n\nThis chapter provided a comprehensive look into the world of software testing,\noffering both theoretical knowledge and hands-on tools for practical implementation.\nOne of the intriguing parts for me was the example on testing the my_sqrt() function. Implementing a square root\nfunction might appear elementary,\nbut the emphasis on the Newton–Raphson method highlighted the process behind it.\n\n#### Use-Case\n\nThe first chapter of the Fuzzing book does a solid job of laying down the basics.\nIt sets the stage for the kind of deep thinking we'll need when we start building the\nChasten tool. By mixing theory with hands-on examples, readers get a good grasp of what's\nahead. This foundation is key, making sure everyone's on the same page as we dive into the\nmore complex parts of the book.\nIt's clear that this chapter is an essential starting point for everything that follows.\n\n\n# Week 2\n\n## SE2\n\n#### Summary\n\nThe article contrasts programming with software engineering, emphasizing three primary distinctions:\ntime, scale, and trade-offs. Time emerges as a crucial factor, with software engineering often focusing\non projects with extended lifespans that shifts in technology or business trends.\nUnlike standalone programming tasks, software engineering is inherently collaborative, \nchallenges related to team dynamics, project\nmanagement, and organizational policies. As projects and teams expand, maintaining efficiency is vital.\nFurthermore, the discipline of software engineering demands intricate decision-making. Engineers face\ncomplex trade-offs, frequently operating within an environment of differing metrics.\n\n#### Reflection\n\nReading this, I can resonate with the aspects of drawbacks and trade-offs in software engineering.\nThis is evident in class where many of my colleagues often have to decide which tasks are more crucial\nto complete. Additionally, time significantly influences our work ethic and decision-making.\nIt's a constant balance of prioritizing immediate needs against long-term objectives.\n\n#### Use-Case\n\nDuring our software development, it's crucial to evaluate the trade-offs of our programming choices.\nUnderstanding the advantages and disadvantages before deployment is vital to ensure we don't\nintroduce issues into our code, and also intergate time-keeping as a habit.\n\n## FB2\n\n#### Summary\n\nTo achieve nearly perfect code coverage, we utilize a technique known as fuzzing.\nFuzzing involves generating random characters to test various input scenarios.\nThis method helps generate potential outcomes for different functions,\nlike the provided example of the cgi_decode function.\nThrough this, we determine the necessary inputs\nto achieve comprehensive code coverage in our tests.\n\n#### Reflection\n\nImplementing such testing mechanisms proves invaluable for identifying\nmaximum coverage using random fuzzing inputs. It's particularly effective\nin discovering edge cases in extensive programs with myriad input possibilities.\nHowever, it's a time-consuming approach. Hence,\nit's crucial to employ this technique only for large-scale programs that can't be\nmanually vetted, ensuring optimal time management.\n\n#### Use-Case\n\nFor our chasten tool, incorporating these tests is paramount,\nespecially as we plan to introduce numerous features throughout the term.\nIt's crucial to ensure thorough coverage before releasing the software.\nIf we decide to implement this testing methodology, we must\nbe prepared to allocate substantial classroom time and personnel to it.\n\n\n# Week 3\n\n## SE3\n\n#### Summary\n\nThis chapter delves into the infrastructure of a software engineering team, emphasizing the pivotal role of\nteamwork in achieving remarkable results and highlighting the significance of self-awareness within the team.\nThe chapter discusses the trade-offs of working alone in software\ndevelopment, including prolonged struggles and delayed error detection.\nIt also introduces the concept of collaborative nirvana, focusing on three\npillars of social interaction: humility, respect, and trust.\nThe action items suggested include regular team meetings and check-ins,\npeer mentoring and knowledge sharing, as well as the importance of acknowledging\neach team member's strengths, celebrating success, and learning from failures.\n\n#### Reflection\n\nThis chapter underscores the critical importance of collaboration and self-awareness\nin software engineering teams. It serves as a reminder that working in isolation can\nlead to challenges and hinder progress.\nEmbracing humility, respect, and trust as guiding principles for social interaction\ncan unlock the full potential of teamwork.\n\n#### Use-Case\n\nThe insights and recommendations from this chapter can be applied\nin various scenarios within a software engineering team. For instance,\nteams can implement regular meetings and check-ins to foster communication\nand collaboration. Peer mentoring and knowledge sharing can be encouraged to\nfacilitate skill development and information exchange. Additionally,\nacknowledging the strengths of each team member,\ncelebrating achievements, and using failures as opportunities for\nlearning can help create a positive and productive team culture.\n\n## FB3\n\n#### Summary\n\nFuzzing is a dynamic testing technique employed to discover defects by generating\na wide array of random inputs and subjecting them relentlessly to a target application.\nThe primary aim is to stress-test the software and unearth unexpected vulnerabilities.\nThis chapter delves into the benefits of fuzzing,\nthe roles of the fuzzer and runner components, and the advantages of applying fuzz testing to external programs.\n\n#### Reflection\n\nThe concept of fuzzing is a powerful tool in the software testing arsenal.\nBy inundating an application with diverse and often unpredictable inputs,\nfuzzing can reveal vulnerabilities that traditional testing methods might overlook. Understanding the mechanics of fuzzing,\nsuch as the fuzzer and runner components, allows testers to tailor their approach to the specific needs of the application.\n\n#### Use-Case\n\nFuzzing is an invaluable technique for identifying vulnerabilities in\nsoftware. The benefits of fuzz testing include uncovering issues like\nbuffer overflows, crashes, and security vulnerabilities. To implement\nfuzzing, the fuzzer component can be customized to generate various \ntypes of inputs, such as numbers or characters. The runner component plays\na critical role in executing the target application with the generated inputs\nand monitoring its behavior.\n\n# Week 4\n\n## SE4\n\n#### Summary\n\nIn software development, effective communication within your team is crucial.\nTeam members are more likely to have solutions to issues because they work on\nthe same project. However, various challenges can hinder this communication,\nsuch as fear of making mistakes, withholding code sections, and dealing with broken code.\nTo address these challenges, the article proposes different communication solutions.\nThe best approach involves comprehensive documentation paired with knowledgeable \nindividuals who can apply this information to specific problems. This ensures a\nwealth of information is available, and team members can get personalized help.\nAdditionally, creating a comfortable environment where team members feel free\nto ask questions is crucial. Assigning mentors to new team members facilitates\none-on-one interactions and promotes growth.\n\n#### Reflection\n\nThis article holds significant importance for our work on the \"Chasten\" project.\nEffective communication is vital, especially given our limited time together each\nweek. While we've managed reasonably well so far, there's room for improvement.\nOften, we struggle to make information widely available, particularly concerning\nindividual pull requests and issues in the issue tracker. This can lead to various problems, such as\ninformation loss when team members are absent or leave, and the need for others\nto review the information, potentially resulting in redoing work. Another in need of improvement is organization\nof all the information that we have gathered, then it can be available to others\nthat would like to add to what we have built.\n\n#### Use-Case\n\nIn the Chasten project, we're taking practical steps to boost collaboration,\ndrawing insights from the article on effective software development team communication. \nWe're focused on creating comprehensive project documentation, implementing a mentorship\nprogram or more leaders for the project, encouraging open communication, refining issue tracking, and centralizing project\ninformation. Our aim is to foster better knowledge sharing, reduce information gaps during\ntransitions, streamline issue resolution, enhance information access, and empower team members to guide one another.\nThrough these efforts, we seek to strengthen our teamwork and productivity in the Chasten project.\n\n\n## FB4\n\n#### Summary \n\nThe section on mutation analysis explores the creation of programs to rigorously test test cases.\nIneffective testing can lead to seemingly complete test coverage while missing essential bug detection.\nTo overcome this, mutation analysis programs are introduced to temporarily inject errors into the code,\nassessing the test cases' bug-finding capabilities. The article exemplifies this with a triangle\nclassification program, standardizing the function through parsing and mutation,\nleading to the replacement of return statements with pass statements to provoke errors and gauge test case accuracy.\n\n#### Reflection\n\nThis article underscores the importance of mutation analysis in the Chasten project,\nwhere accommodating diverse user inputs, including complex XPATH expressions, is\nparamount. Ensuring robust and comprehensive test coverage capable of identifying\na wide array of errors is critical. Furthermore, considering the integration of external functions that simplify\nthe intricacies of mutation analysis into the project's software development can\nmarkedly improve the code's overall quality.\n\n#### Use-Case\n\nIn the context of the Chasten project, implementing mutation analysis is pivotal for bolstering test coverage\nand error detection across a spectrum of user inputs, including XPATH expressions.\nEmbracing the methodologies outlined in this article empowers the project to enhance\nits testing procedures, thereby fortifying its ability to identify diverse types of\nerrors. Furthermore, the integration of external functions that streamline\nthe complexities of mutation analysis can expedite the software development process\n ultimately leading to higher-quality code.\n\n# Week 5\n\n## SE5\n\n#### Summary\n\nThis chapter delves into Google's shortcomings in achieving an inclusive\nstandard and offers a roadmap for future rectification as a collective company\nendeavor. Google's software engineer demographics don't mirror their user base,\nleading to the infusion of biases into their projects, like facial recognition\nsoftware. To address this, the Value Versus Outcomes section presents key\nconsiderations: evaluating the composition of the product development team in\nrelation to the end users, designing for the most challenged user to enhance accessibility,\nscrutinizing data for success, and identifying and preventing future failure points. These\nguidelines amalgamate into a call for software engineers to be part of the solution rather thanthe problem, ultimately\nfostering equity in their endeavors. The chapter also provides reflections and suggestions for further action.\n\n#### Reflection\n\nThis chapter underscores the importance of inclusive workplaces\nfor productivity and bias reduction, with software engineers as\nkey agents of change. It emphasizes the need to address bias, shift from\n\"building for\" to \"building with\" everyone, and tackle systemic tech industry\nissues through psychological safety, multicultural competence, and professional\ngrowth. The chapter highlights the significance of engineers\ncomprehending their products' impact on diverse users,\nemphasizing the value of inclusive work environments and ongoing\nlearning for personal and career development.\n\n#### Use-Case\n\n\nThis chapter underscores the importance of inclusivity in product development,\nemphasizing a user-centric approach and collaboration with diversity experts.\nWhile it may not directly apply to our current project, it's vital for workforce\nreadiness. For Chasten's future users, particularly\nAllegheny College students, we must prioritize code readability and\nuse our experience to improve accessibility for a wider audience.\n\n## FB5\n\n#### Summary\n\nWhen fuzzing programs that accept more than just random inputs,\nlike website URLs, it's crucial to adapt our fuzzer to produce\nrealistic yet incorrect URLs for testing functions related to URLs.\nAttempting to test such functions with entirely random inputs could\ntake years to stumble upon a correct HTTP URL. An effective strategy\ninvolves taking valid inputs and strategically altering specific\ncharacters to create URLs that are incorrect but closely resemble\nthe correct format. This approach allows us to generate a wide\narray of input variations. When these diverse inputs are combined\nwith a runner function, they ensure comprehensive coverage of every\nline within the function under test. Consolidating these techniques\ninto a mutation fuzzing function enables the integration of knowledge\nand methods from mutation analysis, code coverage analysis, and fuzzing\ninto a unified and effective testing approach.\n\n#### Reflection\n\nThis article explores the integration of previously acquired knowledge\ninto a single function known as mutation fuzzing. The importance of\nincorporating these ideas into test cases is emphasized to ensure\ncomprehensive coverage of various XPATH expressions. Mutation fuzzing\nallows for the rapid application of these techniques on a large scale,\nenabling the implementation of tests that would be impractical to conduct \nmanually.\n\n#### Use-case\n\nMutation fuzzing serves as a valuable tool in software testing and security analysis,\nparticularly for applications relying on XPATH expressions. It automates the generation\nof diverse inputs, enabling systematic evaluation and rapid identification of vulnerabilities,\nensuring software robustness. Its scalability and efficiency make it an indispensable\nresource for uncovering edge cases and enhancing security.\n\n# Week 6\n\n## SE6\n\n#### Summary\n\nThe section from \"Software Engineering at Google\" stresses the importance of leadership\nwithin any team, especially in software development contexts. It acknowledges the phenomenon\nwhere engineers, often reluctantly, assume managerial roles. The dual mastery of software\nengineering skills and team management is crucial for success. A key focus is on the subtleties\nof effective management, advocating against micromanagement. Instead, a successful manager\nshould aim to create a supportive work environment, providing flexibility and removing impediments\nto streamline workflows. The importance of maintaining a professional yet approachable relationship\nwith team members is also emphasized, which helps in making tough decisions without compromising\nteam dynamics. The chapter crystallizes its guidance into three fundamental principles for leadership:\nHumility, Trust, and Respect. These principles ensure a leader is supportive and reliable, allowing team\nmembers to focus on their tasks without undue concern about managerial issues.\n\n#### Reflection & Use-case\n\nIn our own setting, the traditional hierarchical structure of managers and subordinates is absent.\nHowever, we often find ourselves in leadership roles within peer-driven projects, particularly when we\npossess specialized knowledge. In these scenarios, it's important to apply the principles of respect and\nhumility. Our approach should be one of collaboration and learning, rather than asserting dominance or\npower. This ensures a more harmonious and productive environment, where knowledge transfer is effective\nand team dynamics are positive. By embracing these values, we can foster a healthy and efficient workspace,\neven in the absence of formal leadership roles.\n\n## FB6\n\n#### Summary\n\nThis chapter focuses on the interplay between formal languages, universal grammars,\nand their role in generating inputs, segueing into a detailed exploration of grammars.\nIt emphasizes the significance of grammars in not only constructing programming languages\nbut also in formulating structured inputs for testing. Defining a grammar allows for the\ncreation of a function that generates random, yet structurally sound inputs, facilitating\nextensive code testing. Nevertheless, this method has its boundaries. To optimize its utility,\n\\mutating these inputs is suggested, providing a more thorough examination of the code's\nconstraints and capabilities.\n\n#### Reflection\n\nThe application of grammars in this context was an unexpected revelation to me,\nhaving not considered this possibility when I initially encountered the concept.\nThe deeper I delve into the Fuzzing Book, the more it resembles assembling pieces\nof a puzzle, each piece contributing to the creation of a robust testing suite.\n\n#### Use-case \n\nAs we venture into our new project, it seems opportune to integrate some of these insights.\nImplementing these grammatical structures to generate test inputs could enhance our testing\nprocess, ensuring a more robust and comprehensive evaluation of our code. It's an intriguing\napproach worth exploring to strengthen our project's overall quality and reliability.\n\n# Week 7\n\n## SE7\n\n#### Summary\n\nThis chapter highlights\nstrategies like identifying limiting factors, making informed trade-offs, and iterating ideas\nto strike a balance. A crucial goal is to develop a self-driving team, reducing the 'bus factor'\nby creating subteams for diverse problem-solving. Additionally, the chapter advises on scaling\nteam sizes based on project demands, ensuring neither team members nor leaders are overwhelmed.\n\n#### Reflection & Use-case\n\nFrom this chapter, the standout insight is that effective management comprises observation\nand listening, with just a little being critical adjustments. This principle discourages micromanagement\nand promotes responsive leadership based on team feedback, fostering efficiency and autonomy.\nHowever, its direct relevance to our Chasten project is limited, as we operate without a set leader,\nassigning tasks within small groups for self-driven progress. While the chapter targets environments\nwith clear leadership hierarchies, its emphasis on minimal but meaningful interventions and team\nautonomy can still offer useful insights for our collaborative efforts in developing the Chasten tool.\n\n## FB7\n\n#### Summary\n\nThe chapter addresses the inefficiencies of the simple_grammar_fuzzer in the Fuzzing Book, highlighting\nits poor time complexity with large inputs and frequent inaccuracies in symbol or parenthesis counts.\nTo remedy this, the introduction of deviation trees is proposed. These trees track the pathways of grammar\nexpansions, enabling the monitoring of each grammar statement's cost. This methodology empowers us to preset\nexpansion limits and determine when to terminate the grammar, effectively controlling input size and reducing evaluation time.\n\n#### Reflection & Action\n\nIncorporating deviation trees revolutionizes grammar fuzzing by imposing input size constraints,\ntransforming it into a practical testing method. Without such limits, grammar fuzzing risks becoming\nan endless process with increasingly large inputs, leading to significant time inefficiencies. This\ninnovation ensures that inputs remain manageable in length and can be processed within reasonable\ntimeframes, greatly enhancing the utility and applicability of this testing technique.\n\n# Week 8\n\n## SE8\n\n#### Summary\n\nIn this section of Software Engineering at Google, the focus is on the strategic application of\nrules to optimize code quality. Rules serve as essential guidelines, distinguishing what should\nbe promoted and what should be avoided. These guidelines also prompt companies to reflect on their\ncore values, enabling the incorporation of these principles into the guidance provided to their workforce.\nA well-defined set of rules is imperative to prevent codebases from becoming chaotic and lacking a discernible pattern.\nStandardizing the execution of projects and managing a company becomes achievable by creating a style guide. This ensures\nalignment across the organization, fostering a unified approach to program implementation.\n\nUltimately, establishing robust rules that are easy to follow while maintaining a consistent set of policies\nwithin the workplace is crucial. These rules form the foundation for the team's approach to future projects,\nensuring steady production over time.\n\n#### Action & Reflection\n\nThis section resonates with our Chasten project, as our team frequently experiences challenges in achieving consensus.\nHaving a concise set of rules could greatly benefit us. For example, implementing rules related to the approval of pull\nrequests and workflow standards could lead to a more consistent and efficient team. Such changes would unify our team,\nstreamlining the collaborative process in team-based software engineering without the need for laborious efforts to seek\nteam members' assistance in specific aspects.\n\n## FB8\n\n#### Summary\n\nIn specific scenarios of fuzz testing, relying solely on a grammar fuzzer may not suffice due to the inherent need\nfor rules in input generation. To address this, employing a parser becomes essential to transform a string input\ninto a derivation tree. A Predicate Expression Grammar (PEG) parser serves this purpose, parsing until it identifies\na rule that aligns with its query. An example is provided below:\n\n```python\nclass PEGParser(Parser):\n    def parse_prefix(self, text):\n        cursor, tree = self.unify_key(self.start_symbol(), text, 0)\n        return cursor, [tree]\n```\n\nWhile PEGParser is effective for finding a single match, in many cases, it is desirable to identify all matches,\nnecessitating a Context-Free Grammar (CFG) parser. This type of parser allows for matching all parts of an input\nduring parsing, as illustrated by the following example:\n\n```\nclass CFGParser(CGFParser):\n    def parse(self, text):\n        cursor, states = self.parse_prefix(text)\n        start = next((s for s in states if s.finished()), None)\n\n        if cursor < len(text) or not start:\n            raise SyntaxError(\"at \" + repr(text[cursor:]))\n\n        forest = self.parse_forest(self.table, start)\n        for tree in self.extract_trees(forest):\n            yield self.prune_tree(tree)\n```\n\n#### Action & Reflection\n\nThese parsers represent a crucial advancement in creating derivation trees from specific seeded inputs.\nThis capability enables the identification of necessary grammars for simulating inputs in future fuzz testing,\nautomating the input-taking process for subsequent fuzzing. In the context of Chasten, integrating PEG and CFG\nparsers enhances the tool's performance by facilitating the\nimportation and seamless implementation of these parsers. These parsers contribute to the creation of concise,\nbranched grammars, leading to faster grammar processing times. The incorporation of more complex parsers allows\nfor the composition of grammars with finer details, without compromising external structures or the program's\noverall significance.\n\n## SE9\n\n#### Summary\n\n\nThis segment of Google's Software Engineering focuses on the pre-merger evaluation of code for the main product.\nIt encompasses insights into the advantages, recommendations, and overall procedures employed by Google to optimize\nthe efficiency and effectiveness of code reviews. Google employs a meticulous approach to guarantee correctness,\nconsistency, extensive knowledge sharing among developers, and comprehensive change tracking. While this process\nincurs costs, it ensures that the codebase adheres to Google's high standards of consistency.\n\nHowever, the journey of code review is not always seamless. Consequently, this section provides valuable\ntips for conducting reviews effectively. Essential to this is maintaining a courteous and professional\ncommunication style to facilitate timely and dispute-free code reviews. Code reviewers are advised to\ncommunicate their review timelines promptly, ensuring that others are not left waiting. Professionalism\nbecomes crucial when disagreements arise between a developer and a reviewer regarding a specific section of\ncode; finding common ground on necessary changes is essential. Emphasizing the importance of modest changes\nis another key point, preventing reviewers from feeling overwhelmed and facilitating swift reviews. Crafting\ninformative commit messages and change descriptions proves instrumental in aiding reviewers' understanding of\nthe nature of the changes. Additionally, prudent resource usage is stressed, advocating for a single reviewer\nand the automation of tasks wherever possible.\n\n#### Action & Reflection\n\nThis section highlights crucial insights into efficient code review practices. One notable aspect that caught\nmy attention pertains to the number of reviewers involved in the process. In our current project, we maintain\na minimum of 3 reviewers, and at times, this number escalates to 5 for a single change. This approach is\nflagged as inefficient in the article, emphasizing that often, reviewers merely skim through the code to\nverify functionality rather than conducting a thorough examination. Consequently, multiple individuals spend\ntime perfunctorily reviewing code that could be adequately handled by a single person. Addressing this\ninefficiency involves considering a shift to single-person reviews, which not only streamlines the process\nbut also holds that individual accountable for timely and accurate reviews.\n\nAnother noteworthy point discusses the importance of precise change descriptions, an area where our\nteam appears to be lacking. Specifically, commit messages and timing are identified as potential weaknesses.\nThe suggestion is to increase the frequency of commits to showcase each incremental change to specific code\nsegments. This practice enables reviewers to track the evolution and improvement of the change step by step,\nfostering a clearer understanding of the development process. Implementing these adjustments could contribute\nto a more streamlined and accountable code review process within our team.\n\n## FB9\n\n#### Summary\nWhen employing tests to intentionally induce code failures or crashes, it's crucial to grasp the underlying\nreasons for the failure and understand the conditions that trigger it. Mere awareness of a broken state isn't\nsufficient; one must delve into the hows and whys of the issue. While running tests, pinpointing the specific\nsegments of the code responsible for problems can be challenging. A fuzzer or mutator-based approach might\nidentify the existence of an issue but often falls short in providing insights into the reasons behind the problem.\n\nTo tackle this, manual exploration can be undertaken, where testing continues until the problem is uncovered.\nAlternatively, a technique known as Delta Debugging can be applied. This method takes the inputs responsible\nfor breaking the test or build and employs a binary search algorithm-like approach. It systematically removes\nparts of the input to determine if the issue persists or is resolved. Delta Debugging aids in identifying the\ncauses of a bug or defect, streamlining more efficient and targeted fixes if necessary.\n\nAn illustrative example of Delta Debugging is found in the [Fuzzingbook](https://www.fuzzingbook.org/):\n\n```python\nclass DeltaDebuggingReducer(CachingReducer):\n    \"\"\"Reduce inputs using delta debugging.\"\"\"\n\n    def reduce(self, inp: str) -> str:\n        \"\"\"Reduce input `inp` using delta debugging. Return reduced input.\"\"\"\n\n        self.reset()\n        assert self.test(inp) != Runner.PASS\n\n        n = 2     # Initial granularity\n        while len(inp) >= 2:\n            start = 0.0\n            subset_length = len(inp) / n\n            some_complement_is_failing = False\n\n            while start < len(inp):\n                complement = inp[:int(start)] + \\\n                    inp[int(start + subset_length):]\n\n                if self.test(complement) == Runner.FAIL:\n                    inp = complement\n                    n = max(n - 1, 2)\n                    some_complement_is_failing = True\n                    break\n\n                start += subset_length\n\n            if not some_complement_is_failing:\n                if n == len(inp):\n                    break\n                n = min(n * 2, len(inp))\n\n        return inp\n```\nThis code takes an input, tests it, and iteratively reduces it until it is minimized to a single character.\nThis approach enhances the specificity and usefulness of debugging outputs, providing better insight into\nthe code's behavior during failures.\n\n\n#### Action & Reflection\n\nThis concept seems somewhat beneficial, but considering the specific context in which we would apply it,\nI find that implementing this idea might involve more effort than the relatively minimal gain it offers.\nWhile it provides assistance, we're not dealing with highly intricate inputs, and the setup time for such a\nconcept may outweigh the benefits compared to manually resolving issues. Nevertheless, the core concept of\nreduction itself holds significance in debugging. It serves as an effective approach to identify problems and\noften contributes to a deeper understanding of the code. However, the automated implementation of this concept\nappears overly complex and may not be worth the effort for projects of the scale we are currently working on.\n\n# Week 9\n\n## SE10\n\n#### Summary\n\nThis section of Google's Software Engineering underscores the crucial role of documentation in enhancing\ncode usage and maintenance. Documentation goes beyond code operations, encompassing descriptive notes and\ntutorials to improve overall readability. While its benefits may not be immediately apparent, neglecting\nor delaying documentation can lead to confusion for future developers. Google emphasizes treating documentation\nlike code, with regular maintenance and adherence to a consistent style. Assigning owners to each documentation\nsection ensures ongoing clarity and long-term viability.\n\nUnderstanding the target audience is vital in documentation creation, considering factors like the audience's\nlevel of development experience and whether documentation is for internal developers or the general public.\nThe choice of documentation style is equally important, ranging from reference documentation and design documents\nto in-depth tutorials and conceptual documentation. Ensuring documentation stays current with regular updates is\nkey to its continued effectiveness, aiding users in comprehending all aspects of the tool. In conclusion, while\ncreating documentation requires initial effort, its long-term benefits in facilitating code understanding and\nusage make it a worthwhile endeavor.\n\n#### Action & Reflection\n\nWithin our Cellveyor team, our documentation efforts have room for improvement. While we've been diligent in\ncommenting on the project's work and incorporating reference documentation within the code, we haven't established a\ndedicated wiki for comprehensive documentation, including tutorials on how Cellveyor operates and reference\ndocumentation detailing the various inputs for its commands. This aspect is certainly an area where enhancement is\npossible, but I believe prioritizing it should come after addressing the remaining issues with the tool itself.\n\n## DB1\n\n#### Summary \n\nIn the inaugural section of the Debugging Book, foundational principles of troubleshooting malfunctioning\nfunctions are introduced. The discussion starts by highlighting counterproductive coding practices, such as\nexcessive print statements, arbitrary changes, and hardcoded inputs. Instead, the emphasis is on a meticulous\ncode review approach, seeking to identify root causes rather than opting for temporary fixes. Effectively\nisolating specific issues from broader exceptions entails scrutinizing generalized errors within a function\nand involves formulating, adjusting, and challenging hypotheses about the program's malfunction. Running tests\nbased on these hypotheses aids in identifying correlated issues that need resolution. Once these issues are\nfound, updating the failed test cases enhances coverage and prevents potential errors in future updates.\nMaintaining a comprehensive log of these steps facilitates the recall of previously explored ideas and actions.\n\n#### Action & Reflection\n\nWhile I already incorporate many of these bug-fixing steps into my process, a significant insight from\nthis article was the emphasis on creating a hypothesis for the reasons behind certain function failures.\nThe suggestion of adopting a higher level of documentation and a structured process for each specific issue\nappears highly beneficial, particularly when tackling complex problems. This approach not only aids in my\nindividual problem-solving but also enhances collaboration when others join in to address the issue. In essence,\nincorporating a more detailed approach within our team's issue-resolution strategy promises to yield substantial\nimprovements.ured process for each specific issue appears highly\nbeneficial, particularly when tackling complex problems. This approach not only aids in my individual\nproblem-solving but also enhances collaboration when others join in to address the issue. In essence,\nincorporating a more detailed approach within our team's issue-resolution strategy promises to yield substantial\nimprovements.\n\n# Week 10\n\n## SE11\n\n#### Summary \n\nThis section delves into testing practices at Google, highlighting the incorporation of automated programs\nto examine their extensive codebase for errors. Automated tests play a crucial role in ensuring code correctness,\noffering enhanced confidence and contributing to a smoother development process. When designing tests, Google\nconsiders their size and scope. Tests can be small, covering one process, medium, encompassing a single machine,\nor large, running on multiple machines or processes. Google advocates a majority of code coverage by narrower\nscope tests for more targeted and effective testing, as larger tests are often weaker and time-consuming.\n\n#### Action & Reflection\n\nThe testing concepts presented in this article are highly beneficial and can be effectively applied to our project, Cellveyor\n. While we have implemented both large and small-scale tests, the crucial insight here is the emphasis on not just expanding\ntest coverage but also prioritizing the creation of high-quality tests capable of handling diverse inputs. A key approach to\nachieving this is by concentrating on essential functions and incorporating fuzzing tests, which provide a variety of example\ninputs to ensure robust testing.\n\n## DB2\n\n#### Summary \n\n\nThis section of the Debugging Book delves into the use of tracers for examining variable states throughout different sections of\ncode. An illustrative example involves simple tracking of variables as the program progresses, enhancing debugging efforts by\nrevealing interactions between various variables. A more detailed version demonstrates tracing at specific points in the code,\noffering insights into variable changes:\n\n```python \nreturn 255 remove_html_markup {'s': 'abc', 'tag': False, 'quote': False, 'out': 'abc', 'c': 'c'}\n```\n\nThis meticulous tracking approach reports each instance of variable changes, providing a comprehensive understanding of program\nbehavior. While effective, this method can be time-consuming. To mitigate this, static code injection is introduced, injecting code\nselectively to trace only the necessary parts of the function, significantly reducing program runtime while maintaining detailed\ninsights into variable changes:\n\n```python\n243     for c in s:\n                                         # c = '/'\n244         assert tag or not quote\n246         if c == '<' and not quote:\n    ...\n255     return out\nremove_html_markup() returns 'x'\n```\n\n#### Action & Reflection\n\nTracing a program proves to be an effective method for monitoring the outputs of individual functions, facilitating the debugging\nprocess by providing insights into how variables interact. However, consistently running a tracer for every output can be inefficient\ndue to the time required to track all variables. Implementing tracers selectively into our project, particularly when errors occur,\nwould be highly beneficial in optimizing the debugging process.\n\n# Week 11\n\n## SE12\n\n#### Summary\n\nThis chapter delves into the concept of unit tests and strategies for their long-term maintenance. Poorly designed tests can pose\nchallenges for engineers when addressing issues arising from brittle tests. To mitigate this, the chapter suggests establishing\na test base that remains unchanged, ensuring that test cases consistently validate a function's input and output without altering\nthe method of achieving this. Preventing functions from being refactored in ways that alter their overall functionality maintains\nthe functional integrity of tests. Testing the public version of the program, rather than the private version, is recommended to\nensure the correct results are delivered to users.\n\nEffective testing also involves running state tests that assess the overall system state after program execution. For instance,\na test adding a user to a database should verify a change in the database to confirm the function's success. Writing clear tests\nwith detailed notes and a distinct purpose enhances their strength and aids engineers in quickly identifying issues. Lastly,\nthe chapter emphasizes the importance of adhering to the DRY principle (Don't Repeat Yourself) by avoiding test or function repetition.\nInstead, tests should be DAMP (Descriptive and Meaningful Phrases), prioritizing larger, more comprehensive tests over multiple similar\ntests with slight deviations to optimize the test suite.\n\n#### Action & Reflection\n\nAll these insights prove invaluable when contemplating the creation of test cases within a large program. The concept that resonated with\nme the most is the emphasis on DRY, advocating against repetition in testing. It is crucial to strive for in-depth tests while maintaining a\nfocus on a specific area of code. I am confident that we can enhance our implementation of these ideas in Cellveyor, ensuring that our test\ncases are not only concise but also free from unnecessary repetition.\n\n## DB3\n\n#### Summary\n\nThis chapter explores the concept of unit tests and their long-term maintenance strategies.\nA poorly designed test can create challenges for engineers, and the chapter suggests establishing\nan unchanging test base to ensure consistent validation of a function's input and output. The focus\nis on preventing functions from being refactored in ways that alter their overall functionality,\nmaintaining the functional integrity of tests. Testing the public version of the program, as\nopposed to the private version, is recommended to ensure the correct results are delivered to users.\nEffective testing includes running state tests that assess the overall system state after program\nexecution. Clear tests with detailed notes and a distinct purpose are encouraged to enhance their\nstrength and aid engineers in quickly identifying issues. Lastly, adherence to the DRY principle\n(Don't Repeat Yourself) and the importance of avoiding test or function repetition is emphasized.\nTests should be DAMP (Descriptive and Meaningful Phrases), prioritizing larger, more comprehensive\ntests over multiple similar tests with slight deviations to optimize the test suite.\n\n#### Action & Reflection\n\nAll these insights are valuable when considering the creation of test cases within a large program.\nThe emphasis on DRY, advocating against repetition in testing, resonates as a crucial concept. Striving\nfor in-depth tests while maintaining a focus on a specific area of code is essential. I am confident that\nwe can enhance our implementation of these ideas in Chasten, ensuring that our test cases are not only concise\nbut also free from unnecessary repetition.\n\n\n# Week 12\n\n## DB4\n\n## Summary\n\nThe introduction to the section on statistical debugging explores the process of debugging a program that intermittently\npasses and fails. The recommended approach involves identifying the lines of code that execute during failures but not\nduring passes, thereby efficiently pinpointing potential bugs and streamlining the debugging process. Utilizing a collector\nfunction helps track all lines executed when a function runs with specific inputs, enabling the identification of\ndifferences in executed lines between passing and failing inputs.\n\nThe method involves ranking lines by suspiciousness, evaluating how frequently certain lines run in a substantial\nset of failing inputs versus passing inputs. With tools like discrete or continuous spectra, developers can highlight\nthe line of code most likely to contain a bug. Statistical debugging techniques extend beyond code coverage, utilizing\nvariables and their changes to analyze failing runs and employing training algorithms to assign values to lines and identify error-prone lines.\n\n## Action & Reflection\n\nThese methods prove highly effective in identifying failure points in programs and can significantly save debugging time.\nWhile the integration of test cases employing these methods into the codebase is uncertain, their potential usefulness in\npinpointing error-prone sections, especially in a codebase the size of Cellveyor's, is evident.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title":"Professional Précis","subtitle":"Author: (Keven M. Duverglas)"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}